{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FINM 33150] Regression Analysis and Quantitative Trading Strategies\\\n",
    "Winter 2022 | Professor Brian Boonstra\n",
    "\n",
    "# Final Project Draft\n",
    "\n",
    "_**Due:** Thursday, February 24th, at 11:00pm\\\n",
    "**Authors:** Ashley Tsoi (atsoi, Student ID: 12286230), Piyush Kontu (), Gauri Kant ()_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fetch and clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import functools\n",
    "import warnings\n",
    "\n",
    "import quandl\n",
    "import json\n",
    "import pandas as pd\n",
    "# import pandas_datareader.data as pdr\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "# import math\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# let plot display in the notebook instead of in a different window\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [21, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. Define the functions to fetch data from Quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-1. Get personal API key** from ../data/APIs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/APIs.json')\n",
    "APIs = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-2. Define helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertCorrectDateFormat(date_text):\n",
    "    try:\n",
    "        dt.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Incorrect date format, should be YYYY-MM-DD\")\n",
    "\n",
    "def calcSixMonthsAgo(date_text):\n",
    "    assertCorrectDateFormat(date_text)\n",
    "    d = dt.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "    return (d + relativedelta(months=-6)).strftime('%Y-%m-%d')\n",
    "\n",
    "def calcNextMonth(month_text):\n",
    "    if type(month_text) == str:\n",
    "        m = dt.datetime.strptime(month_text, '%Y-%m')\n",
    "    else: m = month_text\n",
    "    return (m + relativedelta(months=1)).strftime('%Y-%m')\n",
    "\n",
    "def deleteCSV(sec):\n",
    "    file_name = \"../data_large/EOD/\"+sec\n",
    "    if os.path.isfile(file_name):\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-3. Define function** to retrieve raw data from Quandl\n",
    "\n",
    "**Documentation:**\n",
    "```\n",
    "Zacks Fundamentals Collection B (ZFB)\n",
    "https://data.nasdaq.com/databases/ZFB/documentation\n",
    "https://data.nasdaq.com/databases/ZFB/usage/quickstart/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that retrieves ZFB data from Quandl\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getQuandlZFBData(from_table,secs,start_date,end_date,columns):\n",
    "    # Get data fom Quandl using quandl.get_table\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # from_table    | string                    | FC, FR, MT, MKTV, SHRS, or HDM\n",
    "    # secs          | string / tuple of string  | security ticker(s)\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    # columns       | string / tuple of string  | names of the columns to return\n",
    "    \n",
    "    if secs=='all' or secs==(\"all\",): secs = list(pd.read_csv('../data/zacks-tickers.csv').ticker.unique()) # import all tickers from zacks-tickers\n",
    "\n",
    "    if type(secs)==str: seclen = 1\n",
    "    else: seclen=len(secs)\n",
    "    print(f\"Quandl | START | Retriving Quandl data for {seclen:d} securities from the ZACKS/{from_table} table.\\n\")\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    quandl.ApiConfig.api_key = APIs['Quandl']\n",
    "        \n",
    "    if from_table in ['FC','FR','MKTV','SHRS','HDM']:\n",
    "\n",
    "        data = quandl.get_table('ZACKS/'+from_table,\n",
    "                                ticker = secs, \n",
    "                                per_end_date = {'gte':start_date, 'lte':end_date},\n",
    "                                qopts = {'columns':list(columns)},\n",
    "                                paginate = True)\n",
    "        \n",
    "        if 'per_end_date' in data.columns:\n",
    "            data['per_end_date'] = pd.to_datetime(data['per_end_date'])\n",
    "        if 'filing_date' in data.columns:\n",
    "            data['filing_date'] = pd.to_datetime(data['filing_date'])\n",
    "\n",
    "    elif from_table == 'MT':\n",
    "        data = quandl.get_table('ZACKS/MT',\n",
    "                                ticker = secs, \n",
    "                                qopts = {'columns':list(columns)},\n",
    "                                paginate = True)\n",
    "\n",
    "    else:\n",
    "        print(\"from_table is limited to FC, FR, MT, MKTV, SHRS and HDM\")\n",
    "    \n",
    "        \n",
    "    print(f\"Quandl | DONE  | Returning {len(data):d} rows of data from the ZACKS/{from_table} table.\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def _getZFBDataFromQuandl(secs,start_date,end_date):\n",
    "    # Merged Zacks data in five tables: FC, FR, MT, MKTV, and SHRS\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # secs          | string / tuple of string  | security ticker(s)\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    fc = getQuandlZFBData('FC',secs,start_date,end_date,('ticker','exchange','per_end_date','per_type','zacks_sector_code','basic_net_eps','diluted_net_eps','tot_lterm_debt','net_lterm_debt','filing_date'))\n",
    "    fr = getQuandlZFBData('FR',secs,start_date,end_date,('ticker','exchange','per_end_date','per_type','ret_invst','tot_debt_tot_equity'))\n",
    "    mt = getQuandlZFBData('MT',secs,start_date,end_date,('ticker','ticker_type','asset_type'))\n",
    "    mktv = getQuandlZFBData('MKTV',secs,start_date,end_date,('ticker','per_end_date','per_type','mkt_val'))\n",
    "    shrs = getQuandlZFBData('SHRS',secs,start_date,end_date,('ticker','per_end_date','per_type','shares_out','avg_d_shares'))\n",
    "\n",
    "    # Merge the tables\n",
    "    zacks_1 = fc.merge(fr, how='outer', on=['ticker','exchange','per_end_date','per_type'])\n",
    "    zacks_2 = mktv.merge(shrs, how='outer', on=['ticker','per_end_date','per_type'])\n",
    "    zacks_3 = zacks_1.merge(zacks_2, how='outer', on=['ticker','per_end_date','per_type'])\n",
    "    zacks = zacks_3.merge(mt, how='outer', on='ticker')\n",
    "    \n",
    "    return zacks\n",
    "\n",
    "\n",
    "\n",
    "def _getZFBData(secs,start_date,end_date):\n",
    "    # Return merged Zacks data in five tables: FC, FR, MT, MKTV, and SHRS.\n",
    "    # Securities: all securities in '../data/zacks-tickers.csv'\n",
    "    # If table exists locally, get from CSV. Else download as CSV then get from CSV\n",
    "\n",
    "    path = \"../data_large/Zacks\"\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if type(secs)==str:\n",
    "        secs=(secs,)\n",
    "    \n",
    "    zacks = []\n",
    "    for s in secs:\n",
    "        file_name = path+\"/\"+s+\"_\"+start_date+\"_\"+end_date+\".csv\"\n",
    "        if not os.path.isfile(file_name):\n",
    "            # download as CSV in local directory\n",
    "            print(f\"SAVE   | START | \\\"{s}\\\" does not exist in {path}. Saving from Quandl.\\n\")\n",
    "            _getZFBDataFromQuandl(secs,start_date,end_date).sort_values('per_end_date',ascending=True,ignore_index=True).set_index(['ticker','per_end_date']).to_csv(file_name)\n",
    "            print(\"SAVE   | DONE  | \\n\")\n",
    "\n",
    "        zacks.append(pd.read_csv(file_name))\n",
    "    \n",
    "    zacks = pd.concat(zacks)\n",
    "    if 'per_end_date' in zacks.columns:\n",
    "            zacks['per_end_date'] = pd.to_datetime(zacks['per_end_date'])\n",
    "    if 'filing_date' in zacks.columns:\n",
    "        zacks['filing_date'] = pd.to_datetime(zacks['filing_date'])\n",
    "    if 'Unnamed: 0' in zacks.columns:\n",
    "        zacks.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    \n",
    "    print(\"       | DONE  | Returning {:d} rows of ZACKS data.\\n\".format(len(zacks)))\n",
    "    \n",
    "    return zacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE   | START | \"SPX\" does not exist in ../data_large/Zacks. Saving from Quandl.\n",
      "\n",
      "Quandl | START | Retriving Quandl data for 1 securities from the ZACKS/FC table.\n",
      "\n",
      "Quandl | DONE  | Returning 0 rows of data from the ZACKS/FC table.\n",
      "\n",
      "Quandl | START | Retriving Quandl data for 1 securities from the ZACKS/FR table.\n",
      "\n",
      "Quandl | DONE  | Returning 0 rows of data from the ZACKS/FR table.\n",
      "\n",
      "Quandl | START | Retriving Quandl data for 1 securities from the ZACKS/MT table.\n",
      "\n",
      "Quandl | DONE  | Returning 0 rows of data from the ZACKS/MT table.\n",
      "\n",
      "Quandl | START | Retriving Quandl data for 1 securities from the ZACKS/MKTV table.\n",
      "\n",
      "Quandl | DONE  | Returning 0 rows of data from the ZACKS/MKTV table.\n",
      "\n",
      "Quandl | START | Retriving Quandl data for 1 securities from the ZACKS/SHRS table.\n",
      "\n",
      "Quandl | DONE  | Returning 0 rows of data from the ZACKS/SHRS table.\n",
      "\n",
      "SAVE   | DONE  | \n",
      "\n",
      "       | DONE  | Returning 0 rows of ZACKS data.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>per_end_date</th>\n",
       "      <th>zacks_sector_code</th>\n",
       "      <th>basic_net_eps</th>\n",
       "      <th>diluted_net_eps</th>\n",
       "      <th>tot_lterm_debt</th>\n",
       "      <th>net_lterm_debt</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>exchange</th>\n",
       "      <th>ret_invst</th>\n",
       "      <th>tot_debt_tot_equity</th>\n",
       "      <th>mkt_val</th>\n",
       "      <th>per_type</th>\n",
       "      <th>shares_out</th>\n",
       "      <th>avg_d_shares</th>\n",
       "      <th>ticker_type</th>\n",
       "      <th>asset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, per_end_date, zacks_sector_code, basic_net_eps, diluted_net_eps, tot_lterm_debt, net_lterm_debt, filing_date, exchange, ret_invst, tot_debt_tot_equity, mkt_val, per_type, shares_out, avg_d_shares, ticker_type, asset_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_getZFBData('SPX','2010-01-01','2019-12-31')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation**\n",
    "```\n",
    "End of Day US Stock Prices (EOD)\n",
    "https://data.nasdaq.com/databases/EOD/documentation\n",
    "https://data.nasdaq.com/databases/EOD/usage/quickstart/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that retrieves EOD data from Quandl\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getQuandlEODData(sec,start_date,end_date,columns):\n",
    "    # Get one security (sec)'s data fom Quandl using quandl.get_table\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # sec           | string / list of string   | security ticker\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    # columns       | string / list of string   | columns to return\n",
    "    \n",
    "    print(f\"Quandl | START | Retriving Quandl data for security: {sec}\\n\")\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    quandl.ApiConfig.api_key = APIs['Quandl']\n",
    "    data = quandl.get_table('QUOTEMEDIA/PRICES',\n",
    "                            ticker = sec, \n",
    "                            date = {'gte':start_date, 'lte':end_date},\n",
    "                            qopts = {'columns':list(set(['date','ticker']+list(columns)))}\n",
    "                            )\n",
    "\n",
    "    data.date = pd.to_datetime(data.date, unit='D')\n",
    "    data.set_index(['date','ticker'],inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "    # data.index = pd.to_datetime(data.index, unit='D')\n",
    "    \n",
    "    print(f\"Quandl | DONE  | Returning {len(data):d} dates of data for {sec}.\\n\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quandl | START | Retriving Quandl data for security: ('SCHB', 'VEA', 'VWO', 'FM', 'GLD', 'SLV', 'USO', 'UNG', 'DBA', 'COW', 'GOVT', 'TIP', 'MBB', 'LQD', 'HYG', 'BNDX', 'EMB', 'VNQ', 'PSP', 'BIL')\n",
      "\n",
      "Quandl | DONE  | Returning 3526 dates of data for ('SCHB', 'VEA', 'VWO', 'FM', 'GLD', 'SLV', 'USO', 'UNG', 'DBA', 'COW', 'GOVT', 'TIP', 'MBB', 'LQD', 'HYG', 'BNDX', 'EMB', 'VNQ', 'PSP', 'BIL').\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "      <th>adj_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <th>BIL</th>\n",
       "      <td>85.2938</td>\n",
       "      <td>29450.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <th>BIL</th>\n",
       "      <td>85.2380</td>\n",
       "      <td>30500.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <th>BIL</th>\n",
       "      <td>85.2201</td>\n",
       "      <td>173200.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <th>BIL</th>\n",
       "      <td>85.2936</td>\n",
       "      <td>30300.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <th>BIL</th>\n",
       "      <td>85.2342</td>\n",
       "      <td>18350.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <th>BIL</th>\n",
       "      <td>91.4300</td>\n",
       "      <td>730397.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <th>BIL</th>\n",
       "      <td>91.4200</td>\n",
       "      <td>1932997.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <th>BIL</th>\n",
       "      <td>91.4200</td>\n",
       "      <td>1246326.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <th>BIL</th>\n",
       "      <td>91.4300</td>\n",
       "      <td>836968.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <th>BIL</th>\n",
       "      <td>91.4300</td>\n",
       "      <td>871356.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3526 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   adj_close   adj_volume\n",
       "date       ticker                        \n",
       "2008-01-02 BIL       85.2938   29450.0000\n",
       "2008-01-03 BIL       85.2380   30500.0000\n",
       "2008-01-04 BIL       85.2201  173200.0000\n",
       "2008-01-07 BIL       85.2936   30300.0000\n",
       "2008-01-08 BIL       85.2342   18350.0000\n",
       "...                      ...          ...\n",
       "2021-12-27 BIL       91.4300  730397.0000\n",
       "2021-12-28 BIL       91.4200 1932997.0000\n",
       "2021-12-29 BIL       91.4200 1246326.0000\n",
       "2021-12-30 BIL       91.4300  836968.0000\n",
       "2021-12-31 BIL       91.4300  871356.0000\n",
       "\n",
       "[3526 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secs = ('SCHB','VEA','VWO','FM','GLD','SLV','USO','UNG','DBA','COW','GOVT','TIP','MBB','LQD','HYG','BNDX','EMB','VNQ','PSP','BIL')\n",
    "\n",
    "# secs = ('VEA','VWO')\n",
    "start_date,end_date = '2008-01-01','2022-01-01'\n",
    "\n",
    "data = getQuandlEODData(secs,start_date,end_date,('adj_close','adj_volume'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-4. Define function** to filter / clean raw data\n",
    "\n",
    "**Requirements:**\n",
    "```\n",
    "- US Equities\n",
    "- not in the automotive, financial or insurance sector over the entire period\n",
    "- end-of-day adjusted closing prices are available over the entire period\n",
    "- debt/market cap ratio is greater than 0.1\n",
    "- has feasible calculation of the ratios over the entire period: \n",
    "  - debt to market cap, \n",
    "  - return on investment, and \n",
    "  - price to earnings. \n",
    "  Including for at least one PER END DATE no more than one year old. Debt ratio of zero is OK.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanZFBData(secs,start_date,end_date):\n",
    "\n",
    "    # === GET RAW DATA ============================================\n",
    "\n",
    "    zacks = _getZFBData(secs,start_date,end_date)\n",
    "    zacks['date'] = zacks['filing_date']\n",
    "    \n",
    "    # === FILTER / CLEAN ==========================================\n",
    "    \n",
    "    # US Equities only\n",
    "    zacks = zacks[zacks.exchange.isin(('NYSE','NASDAQ'))]   # select US stock exchanges\n",
    "    zacks = zacks[zacks.ticker_type=='S']                   # S = Securities\n",
    "    zacks = zacks[zacks.asset_type=='COM'][zacks.columns]   # COM = Common stocks\n",
    "\n",
    "    # remove tickers without filing dates (tickers without filing dates are impossible to join on)\n",
    "    filingDate_filter = zacks[pd.isnull(zacks.filing_date)].ticker.unique()\n",
    "    zacks = zacks[~zacks.ticker.isin(filingDate_filter)]\n",
    "    \n",
    "    # not in the automotive, financial or insurance sector for any date (NOTE: there might be sector changes)\n",
    "    sector_filter = zacks[zacks.zacks_sector_code.isin((5,13))].ticker.unique() # 5 = automotive, 13 = finance (includes insurance)\n",
    "    zacks = zacks[~zacks.ticker.isin(sector_filter)]\n",
    "    \n",
    "    # Debt -- Use net debt where available, total debt otherwise\n",
    "    zacks['debt'] = zacks.net_lterm_debt.fillna(zacks.tot_lterm_debt)\n",
    "\n",
    "    # EPS -- use the basic version (GAAP) if no diluted number is available.\n",
    "    zacks['eps'] = zacks.diluted_net_eps.fillna(zacks.basic_net_eps)\n",
    "    zacks.eps.clip(lower=0.001, inplace=True) # make all negative eps 0.001\n",
    "\n",
    "    # If have both quarterly & annual data for the same ticker & date, use quarterly\n",
    "    ratio_cols = ['tot_debt_tot_equity','mkt_val','ret_invst','debt','eps','shares_out','avg_d_shares']\n",
    "    zacks.set_index(['ticker','date'],inplace=True)\n",
    "    zacks_quarterly = zacks[zacks.per_type=='Q']\n",
    "    zacks_annual = zacks[zacks.per_type=='A']\n",
    "    for c in ratio_cols:\n",
    "        zacks_quarterly[c] = zacks_quarterly[c].fillna(zacks_annual[c])\n",
    "    zacks = zacks_quarterly.reset_index()\n",
    "    \n",
    "    # debt-to-market-cap ratio greater than 0.1 AND not null (filter all since we will have enough tickers)\n",
    "    badDebtToMC_filter = zacks[(zacks.tot_debt_tot_equity<=0.1) | (pd.isnull(zacks.tot_debt_tot_equity))].ticker.unique()\n",
    "    zacks = zacks[~zacks.ticker.isin(badDebtToMC_filter)]\n",
    "\n",
    "    # other ratios are not null (ret_invst, mkt_val, eps, debt)\n",
    "    nullRatio_filter = list(zacks[pd.isnull(zacks.ret_invst) | pd.isnull(zacks.mkt_val)].ticker.unique())\n",
    "    nullRatio_filter += list(zacks[pd.isnull(zacks.eps) | pd.isnull(zacks.debt)].ticker.unique())\n",
    "    zacks = zacks[~zacks.ticker.isin(set(nullRatio_filter))]\n",
    "    \n",
    "    column_order = ['ticker','date','per_end_date','filing_date',\n",
    "                    'zacks_sector_code',\n",
    "                    'basic_net_eps','diluted_net_eps','eps',\n",
    "                    'tot_lterm_debt','net_lterm_debt','debt',\n",
    "                    'tot_debt_tot_equity','ret_invst','mkt_val',\n",
    "                    'shares_out','avg_d_shares']\n",
    "    return zacks[column_order].sort_values('date',ascending=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getEodFundamentalData(secs,start_date,end_date):\n",
    "    \n",
    "    before_start_date = calcSixMonthsAgo(start_date) # get data for 6 extra months before start_date to get data reported by start_date\n",
    "\n",
    "    ZFB_file_name = '../data_large/clean/ZFB.csv'\n",
    "    if not os.path.isfile(ZFB_file_name):\n",
    "        zacks = getCleanZFBData(secs,before_start_date,end_date)\n",
    "        repeatFilingDate_filter = zacks.loc[zacks[['ticker','date']].duplicated()].ticker.unique()\n",
    "        zacks = zacks[~zacks.ticker.isin(repeatFilingDate_filter)]\n",
    "        zacks.set_index(['ticker','date']).to_csv(ZFB_file_name)\n",
    "    else:\n",
    "        zacks = pd.read_csv(ZFB_file_name)\n",
    "\n",
    "    tickers = tuple(zacks.ticker.unique())\n",
    "    noEOD_filter = set()\n",
    "    prices_file_name = '../data_large/clean/prices.csv'\n",
    "    if not os.path.isfile(prices_file_name):\n",
    "        prices = getAdjClose(tickers,before_start_date,end_date)\n",
    "\n",
    "        # end-of-day adjusted closing prices are available\n",
    "        for sec in tickers:\n",
    "            price = prices.iloc[prices.index.get_level_values('ticker') == sec]\n",
    "            data_len = len(price)\n",
    "            if data_len < 1910 or any(pd.isnull(price.adj_close.loc[start_date:end_date])): # 1910 = number of trading days in the period 2013-07-01 -- 2021-01-31\n",
    "                # filter out the security\n",
    "                noEOD_filter.add(sec)\n",
    "                if data_len > 0: pd.DataFrame(columns=['date','ticker','adj_close']).to_csv('../data_large/EOD/'+sec) # make csv of filtered securities an empty table so we skip downloading next time\n",
    "    \n",
    "        prices = prices.iloc[~prices.index.get_level_values('ticker').isin(noEOD_filter)]\n",
    "\n",
    "        prices.to_csv(prices_file_name)\n",
    "    else:\n",
    "        prices = pd.read_csv(prices_file_name,index_col=['ticker','date'])\n",
    "    \n",
    "    zacks = zacks[~zacks.ticker.isin(noEOD_filter)]\n",
    "\n",
    "    # get per_end_date_price\n",
    "    zacks = zacks.join(prices.rename(index={'date':'per_end_date'}),on=['ticker','per_end_date']).rename(columns={'adj_close':'per_end_date_price'})\n",
    "    \n",
    "    # === JOIN PRICING DATA with FUNDAMENTAL DATA =================\n",
    "    \n",
    "    zacks.set_index(['ticker','date'],inplace=True)\n",
    "    data = pd.concat([prices,zacks], axis=1)\n",
    "    \n",
    "    # === CALCULATE / RECALCULATE RATIOS ==========================\n",
    "\n",
    "    # forward fill everything\n",
    "    data = data.transform(lambda v: v.ffill())\n",
    "\n",
    "    # add returns\n",
    "    data['return'] = data.adj_close.pct_change()\n",
    "\n",
    "    # PE (price to earnings)\n",
    "    data['PE'] = data.adj_close / data.eps\n",
    "\n",
    "    # DE (debt to market cap)\n",
    "    data['DE'] = data.tot_debt_tot_equity * data.per_end_date_price / data.adj_close\n",
    "\n",
    "    # ROI (return on investment)\n",
    "    data['mkt_val_daily'] = data.mkt_val * data.adj_close / data.per_end_date_price\n",
    "    data['ROI'] = data.ret_invst * (data.debt+data.mkt_val) / (data.debt+data.mkt_val_daily)\n",
    "\n",
    "    # Fourth ratio -- want low PE, low DE, and high ROI\n",
    "    data['combo'] = -0.5*data.PE - 0.5*data.DE + 2*data.ROI\n",
    "\n",
    "    # Get changes in ratios\n",
    "    for c in ['PE','DE','ROI','combo']:\n",
    "        data[c+'_delta'] = data[c].diff()\n",
    "\n",
    "    # === FINAL CLEAN-UP ==========================================\n",
    "\n",
    "    # Make sure the index is datetime\n",
    "    data.index = data.index.set_levels(pd.to_datetime(data.index.levels[1]), level=1)\n",
    "    \n",
    "    # === RETURN DATA =============================================\n",
    "    \n",
    "    index_ticker = data.index.get_level_values('ticker').unique()\n",
    "    print(f'Returning EOD + fundamental data for {len(index_ticker)} tickers.')\n",
    "\n",
    "    columns = ['adj_close','return','PE','PE_delta','DE','DE_delta','ROI','ROI_delta','combo','combo_delta']\n",
    "    index_date = data.index.get_level_values('date')\n",
    "    return data[columns].loc[(index_date>=start_date) & (index_date<=end_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. Fetch cleaned data using the functions above\n",
    "\n",
    "**Dates:**\n",
    "```\n",
    "January 1, 2000 - January 31, 2021*\n",
    "```\n",
    "\n",
    "**1-3-1. Fetch data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs,start_date,end_date = ('all','2014-01-01','2021-01-31')\n",
    "secData = getEodFundamentalData(secs,start_date,end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot check the data against sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = secData.loc[('LLY','2020-06-30')]\n",
    "assert np.isclose(l.PE, 100.062297)\n",
    "assert np.isclose(l.DE, 4.532301)\n",
    "assert np.isclose(l.ROI, 7.127691)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define function to get repo rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that retrieves data from Quandl\n",
    "def getQuandlFredData(table,start_date,end_date):\n",
    "    # Get one security (sec)'s data fom Quandl using quandl.get_table\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # table         | string                    | [database]/[table]\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    \n",
    "    print(\"Quandl | START | Retriving Quandl data for table: \\n\",table)\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    quandl.ApiConfig.api_key = APIs['Quandl']\n",
    "    data = quandl.get('FRED/'+table,\n",
    "                      start_date=start_date, end_date=end_date\n",
    "                      )\n",
    "\n",
    "    print(\"Quandl | DONE  | Returning {:d} dates of data for {}.\\n\".format(len(data),table))\n",
    "    return data\n",
    "\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getRepo(start_date,end_date):\n",
    "    \n",
    "    ted = getQuandlFredData(\"TEDRATE\", start_date=start_date, end_date=end_date).rename(columns={'Date':'date','Value':'ted'})\n",
    "    tbill = getQuandlFredData(\"DTB3\", start_date=start_date, end_date=end_date).rename(columns={'Date':'date','Value':'tbill_3m'})\n",
    "\n",
    "    repo = ted.merge(tbill, how='inner', on='Date').rename(index={'Date':'date'})\n",
    "    repo['repo'] = repo.ted + repo.tbill_3m - 0.01 # repo rate = funding rate minus 100bp\n",
    "\n",
    "    rf = pd.read_csv(\"../data/F-F_Research_Data_Factors_daily.csv\")[['Unnamed: 0','RF']].rename(columns={'Unnamed: 0':'date'})\n",
    "    rf['date'] = rf.date.apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "    rf = rf.set_index('date').loc[start_date:end_date]\n",
    "\n",
    "    return pd.concat([repo,rf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secData = getEodFundamentalData(secs,start_date,end_date)\n",
    "data = secData.join(getRepo('2014-01-01','2021-01-31'), on='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Trade simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze performance of a top-and-bottom decile trading strategy. Now rank based on changes in your ratios rather than the ratios themselves. Play with the effects of sizing positions by rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDecilePosition(periodData,ratio,buyLow=True):\n",
    "    \n",
    "    # Return list of 'position'\n",
    "    # set lowest 3 deciles' position as 1,\n",
    "    #     highest 3 deciles' position as -1\n",
    "    #     middle 4 are 0\n",
    "    # flip the positions if buyLow=False\n",
    "    \n",
    "    buyLow = 1 if buyLow else -1\n",
    "    decile = pd.qcut(periodData.groupby('ticker').mean()[ratio], 10, labels=False).to_frame()\n",
    "    decile['position'] = buyLow*[1 if d<3 else -1 if d>6 else 0 for d in decile[ratio]]    \n",
    "\n",
    "    return periodData.join(decile[['position']], on='ticker')['position'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tradeRatioDecile(data,ratio,buyLow=True):\n",
    "\n",
    "    # Get positions for all securities, all dates, for the inputted ratio. \n",
    "    # 1 = buy, 0 = no position, -1 = sell\n",
    "\n",
    "    data = data.swaplevel(0,1).sort_index(level=0,ascending=True) # date is now at level 0\n",
    "    # recalculate decile every month\n",
    "    months = data.index.get_level_values('date').to_period('M')\n",
    "    for m in months:\n",
    "        periodData = data.loc[m:calcNextMonth(m)][[ratio]]\n",
    "        periodData = periodData.join(getDecilePosition(periodData,'PE',buyLow))\n",
    "        data = data.join(periodData[['position']])\n",
    "    \n",
    "    data = data.swaplevel(0,1).sort_index(level=0,ascending=True) # ticker is now at level 0\n",
    "    # update signal for every security\n",
    "    tickers = data.index.get_level_values('ticker').unique()\n",
    "    for t in tickers:\n",
    "        pos = data.loc[t]['position']\n",
    "        data.loc[t,'signal'] = [pos[0]] + pos.diff()[1:].tolist()\n",
    "\n",
    "    return data.rename(columns={'signal':ratio+'_signal','position':ratio+'_position'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buyInstuction = {\n",
    "        # ratio : buyLow\n",
    "        'PE':True,\n",
    "        'PE_delta':True,\n",
    "        'DE':True,\n",
    "        'DE_delta':True,\n",
    "        'ROI':False,\n",
    "        'ROI_delta':True,\n",
    "        'Combo':False,\n",
    "        'Combo_delta':True\n",
    "    }\n",
    "\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def tradeSimulation(secs,start_date,end_date,ratio,buyLow,K=1000000):\n",
    "    \n",
    "    # Trade -- get monthly trade positions\n",
    "    # Get positions for all securities, all dates, for the inputted ratio. \n",
    "    # 1 = buy, 0 = no position, -1 = sell\n",
    "\n",
    "    secData = getEodFundamentalData(secs,start_date,end_date)\n",
    "    data = secData.join(getRepo(start_date,end_date), on='date')\n",
    "    data['signal'] = 0\n",
    "    data['position'] = 0\n",
    "    \n",
    "    data = data.swaplevel(0,1).sort_index(level=0,ascending=True) # date is now at level 0\n",
    "    # recalculate decile every month\n",
    "    months = [str(m) for m in data.index.get_level_values('date').to_period('M').unique()]\n",
    "    for m in months:\n",
    "        periodData = data.loc[m,[ratio]]\n",
    "        periodData['position'] = getDecilePosition(periodData,ratio,buyLow)\n",
    "        lastDate = max(periodData.index.get_level_values('date').unique()),\n",
    "        periodData.loc[lastDate,'position'] = [0]*len(periodData.loc[lastDate]) # set all end-of-month position to 0\n",
    "        data.loc[m,'position'] = periodData['position']\n",
    "    \n",
    "    data.fillna(method='ffill',inplace=True)\n",
    "\n",
    "    data = data.swaplevel(0,1).sort_index(level=0,ascending=True) # ticker is now at level 0\n",
    "    # update signal for every security\n",
    "    tickers = data.index.get_level_values('ticker').unique()\n",
    "    for t in tickers:\n",
    "        pos = data.loc[t]['position']\n",
    "        data.loc[t,'signal'] = [pos[0]] + pos.diff()[1:].tolist()\n",
    "    \n",
    "    tradeSim = pd.DataFrame(index=data.index.get_level_values('date').unique(),columns=['buy_total_price','sell_total_price','repo','cash','total_value','PnL'])\n",
    "\n",
    "    data = data.swaplevel(0,1).sort_index(level=0,ascending=True) # date is now at level 0\n",
    "    for m in months:\n",
    "        md = data.loc[m,'adj_close'].sum()\n",
    "\n",
    "        return md\n",
    "        \n",
    "    print('calculated trade signal and positions')\n",
    "\n",
    "    return tradeSim\n",
    "    \n",
    "    # Initiate columns\n",
    "    K_balances = [K]\n",
    "    total_values = [K]\n",
    "    PnL_daily_list, PnL_cumulative_list = [], []\n",
    "    for i,row in tradeSim.iterrows(): # current columns: adj_close for both securities, spread, quantities to buy\n",
    "\n",
    "        # Calculate present position value (but don't append to list yet since it may hit stop-loss limit)\n",
    "        if signal: # if there's a new signal\n",
    "            position_quantity = position*row['quantity'] # quantity = new position's quantity\n",
    "\n",
    "        else: # if no signal, position quantity = previous position quantity (unless stop-loss limit is triggered later)\n",
    "            position_quantity = position_quantities[-1]\n",
    "\n",
    "        # Security buy amounts (but don't append to list yet since it may hit stop-loss limit)\n",
    "        secX_position_value = position_quantity*row[secs[0]+'_adj_close']\n",
    "        secY_position_value = -1*position_quantity*row[secs[1]+'_adj_close']\n",
    "        position_value = secX_position_value + secY_position_value\n",
    "        \n",
    "        # Cash balances and total values (if doesn't hit stop-loss limit)\n",
    "        K_balance = K_balances[-1] - position_value\n",
    "        total_value = position_value + K_balance\n",
    "        total_value_delta = total_value-total_values[-1]\n",
    "\n",
    "        # PnLs (daily and cumulative)\n",
    "        PnL_daily = total_value_delta/total_values[-1]\n",
    "        PnL_cumulative = total_value/K - 1\n",
    "\n",
    "        # update prev_position for next calculation\n",
    "        prev_position = position\n",
    "        \n",
    "        # Append new variables into lists\n",
    "        positions.append(position)\n",
    "        signals.append(signal)\n",
    "        position_quantities.append(position_quantity)\n",
    "        position_values.append(position_value)\n",
    "        K_balances.append(K_balance)\n",
    "        total_values.append(total_value)\n",
    "        PnL_daily_list.append(PnL_daily)\n",
    "        PnL_cumulative_list.append(PnL_cumulative)\n",
    "\n",
    "    # Save the data in tradeSim table\n",
    "    tradeSim['position'] = positions[1:]\n",
    "    tradeSim['position_value'] = position_values[1:]\n",
    "    tradeSim['cash'] = K_balances[1:]\n",
    "    tradeSim['total_value'] = total_values[1:]\n",
    "    tradeSim['PnL_daily'] = PnL_daily_list\n",
    "    tradeSim['PnL_cumulative'] = PnL_cumulative_list\n",
    "    \n",
    "    # print(\"trade  | DONE  | \\n\")\n",
    "\n",
    "    # keep a record of params\n",
    "    summary = {'data':  ['security_X','security_Y','start_date','end_date','N_window','M','j','g','s','K','final_value','PnL_daily_max','PnL_cumulative'],\n",
    "               'value': [secs[0],secs[1],start_date,end_date,N_window,M,j,g,s,K,total_values[-1],max(PnL_daily_list),PnL_cumulative_list[-1]]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary).set_index('data')\n",
    "        \n",
    "    return summary_df,tradeSim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = []\n",
    "for r,buyLow in buyInstuction:\n",
    "    trade.append(tradeSimulation(secs,start_date,end_date,r,buyLow))\n",
    "trades = pd.concat(trade,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTradeSim(tradeSim):\n",
    "    \n",
    "    plt.clf() # clear previous plots\n",
    "\n",
    "    tp = plt\n",
    "\n",
    "    tp.title('Cumulative Return')\n",
    "\n",
    "    tp.plot(tradeSim['cumret_spread'], label='cumulative return spread')\n",
    "    \n",
    "    tp.plot(tradeSim['cumret_spread'][tradeSim['signal']>1], color='green', marker='o', markersize=6, linestyle='none')\n",
    "    tp.plot(tradeSim['cumret_spread'][tradeSim['signal']==1], color='green', marker='o', markersize=4, linestyle='none', label='buy signal')\n",
    "    tp.plot(tradeSim['cumret_spread'][tradeSim['signal']==-1], color='red', marker='o', markersize=4, linestyle='none', label='sell signal')\n",
    "    tp.plot(tradeSim['cumret_spread'][tradeSim['signal']<-1], color='red', marker='o', markersize=6, linestyle='none')\n",
    "    \n",
    "    tp.plot(tradeSim['cumret_spread'][tradeSim['stop_loss_trigger']], color='blue', marker='o', markersize=6, linestyle='none', label='stop-loss signal')\n",
    "\n",
    "    tp.legend()\n",
    "\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ff398735b840e154b8cbd654a97af1eda1e82713cbff18c7e563bf43d4f2a36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
