{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FINM 33150] Regression Analysis and Quantitative Trading Strategies\\\n",
    "Winter 2022 | Professor Brian Boonstra\n",
    "\n",
    "# HW #3 Financial Ratio Quantile Strategies\n",
    "\n",
    "_**Due:** Thursday, February 3rd, at 11:00pm\\\n",
    "**Name:** Ashley Tsoi (atsoi, Student ID: 12286230)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fetch and clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import functools\n",
    "import warnings\n",
    "\n",
    "import quandl\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# let plot display in the notebook instead of in a different window\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [21, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. Define the functions to fetch data from Quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-1. Get my personal keys** from ../data/APIs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/APIs.json')\n",
    "APIs = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-2. Define helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertCorrectDateFormat(date_text):\n",
    "    try:\n",
    "        dt.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Incorrect date format, should be YYYY-MM-DD\")\n",
    "\n",
    "def calcSixMonthsAgo(date_text):\n",
    "    assertCorrectDateFormat(date_text)\n",
    "    d = dt.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "    return (d + relativedelta(months=-6)).strftime('%Y-%m-%d')\n",
    "\n",
    "def deleteCSV(sec):\n",
    "    file_name = \"../data_large/EOD/\"+sec\n",
    "    if os.path.isfile(file_name):\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-3. Define function** to retrieve raw data from Quandl\n",
    "\n",
    "**Documentation:**\n",
    "```\n",
    "Zacks Fundamentals Collection B (ZFB)\n",
    "https://data.nasdaq.com/databases/ZFB/documentation\n",
    "https://data.nasdaq.com/databases/ZFB/usage/quickstart/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that retrieves ZFB data from Quandl\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getQuandlZFBData(from_table,secs,start_date,end_date,columns):\n",
    "    # Get data fom Quandl using quandl.get_table\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # from_table    | string                    | FC, FR, MT, MKTV, SHRS, or HDM\n",
    "    # secs          | string / tuple of string  | security ticker(s)\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    # columns       | string / tuple of string  | names of the columns to return\n",
    "    \n",
    "    if secs=='all' or secs==(\"all\",): secs = list(pd.read_csv('../data/zacks-tickers.csv').ticker.unique()) # import all tickers from zacks-tickers\n",
    "\n",
    "    if type(secs)==str: seclen = 1\n",
    "    else: seclen=len(secs)\n",
    "    print(f\"Quandl | START | Retriving Quandl data for {seclen:d} securities from the ZACKS/{from_table} table.\\n\")\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    quandl.ApiConfig.api_key = APIs['Quandl']\n",
    "        \n",
    "    if from_table in ['FC','FR','MKTV','SHRS','HDM']:\n",
    "\n",
    "        data = quandl.get_table('ZACKS/'+from_table,\n",
    "                                ticker = secs, \n",
    "                                per_end_date = {'gte':start_date, 'lte':end_date},\n",
    "                                qopts = {'columns':list(columns)},\n",
    "                                paginate = True)\n",
    "        \n",
    "        if 'per_end_date' in data.columns:\n",
    "            data['per_end_date'] = pd.to_datetime(data['per_end_date'])\n",
    "        if 'filing_date' in data.columns:\n",
    "            data['filing_date'] = pd.to_datetime(data['filing_date'])\n",
    "\n",
    "    elif from_table == 'MT':\n",
    "        data = quandl.get_table('ZACKS/MT',\n",
    "                                ticker = secs, \n",
    "                                qopts = {'columns':list(columns)},\n",
    "                                paginate = True)\n",
    "\n",
    "    else:\n",
    "        print(\"from_table is limited to FC, FR, MT, MKTV, SHRS and HDM\")\n",
    "    \n",
    "        \n",
    "    print(f\"Quandl | DONE  | Returning {len(data):d} rows of data from the ZACKS/{from_table} table.\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def _getZFBDataFromQuandl(secs,start_date,end_date):\n",
    "    # Merged Zacks data in five tables: FC, FR, MT, MKTV, and SHRS\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # secs          | string / tuple of string  | security ticker(s)\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    fc = getQuandlZFBData('FC',secs,start_date,end_date,('ticker','exchange','per_end_date','per_type','zacks_sector_code','basic_net_eps','diluted_net_eps','tot_lterm_debt','net_lterm_debt','filing_date'))\n",
    "    fr = getQuandlZFBData('FR',secs,start_date,end_date,('ticker','exchange','per_end_date','per_type','ret_invst','tot_debt_tot_equity'))\n",
    "    mt = getQuandlZFBData('MT',secs,start_date,end_date,('ticker','ticker_type','asset_type'))\n",
    "    mktv = getQuandlZFBData('MKTV',secs,start_date,end_date,('ticker','per_end_date','per_type','mkt_val'))\n",
    "    shrs = getQuandlZFBData('SHRS',secs,start_date,end_date,('ticker','per_end_date','per_type','shares_out','avg_d_shares'))\n",
    "\n",
    "    # Merge the tables\n",
    "    zacks_1 = fc.merge(fr, how='outer', on=['ticker','exchange','per_end_date','per_type'])\n",
    "    zacks_2 = mktv.merge(shrs, how='outer', on=['ticker','per_end_date','per_type'])\n",
    "    zacks_3 = zacks_1.merge(zacks_2, how='outer', on=['ticker','per_end_date','per_type'])\n",
    "    zacks = zacks_3.merge(mt, how='outer', on='ticker')\n",
    "    \n",
    "    return zacks\n",
    "\n",
    "\n",
    "\n",
    "def _getZFBData(secs,start_date,end_date):\n",
    "    # Return merged Zacks data in five tables: FC, FR, MT, MKTV, and SHRS.\n",
    "    # Securities: all securities in '../data/zacks-tickers.csv'\n",
    "    # Date: 2013-07-01 -- 2021-01-31\n",
    "    # If table exists locally, get from CSV. Else download as CSV then get from CSV\n",
    "\n",
    "    path = \"../data_large/Zacks\"\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if type(secs)==str:\n",
    "        secs=(secs,)\n",
    "    \n",
    "    zacks = []\n",
    "    for s in secs:\n",
    "        file_name = path+\"/\"+s+\"_\"+start_date+\"_\"+end_date+\".csv\"\n",
    "        if not os.path.isfile(file_name):\n",
    "            # download as CSV in local directory\n",
    "            print(f\"SAVE   | START | \\\"{s}\\\" does not exist in {path}. Saving from Quandl.\\n\")\n",
    "            _getZFBDataFromQuandl(secs,start_date,end_date).set_index(['ticker','per_end_date']).to_csv(file_name)\n",
    "            print(\"SAVE   | DONE  | \\n\")\n",
    "\n",
    "        zacks.append(pd.read_csv(file_name))\n",
    "    \n",
    "    zacks = pd.concat(zacks)\n",
    "    if 'per_end_date' in zacks.columns:\n",
    "            zacks['per_end_date'] = pd.to_datetime(zacks['per_end_date'])\n",
    "    if 'filing_date' in zacks.columns:\n",
    "        zacks['filing_date'] = pd.to_datetime(zacks['filing_date'])\n",
    "    \n",
    "    print(\"       | DONE  | Returning {:d} rows of ZACKS data.\\n\".format(len(zacks)))\n",
    "    \n",
    "    return zacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documentation**\n",
    "```\n",
    "End of Day US Stock Prices (EOD)\n",
    "https://data.nasdaq.com/databases/EOD/documentation\n",
    "https://data.nasdaq.com/databases/EOD/usage/quickstart/python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that retrieves EOD data from Quandl\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getQuandlEODData(sec,start_date,end_date,columns):\n",
    "    # Get one security (sec)'s data fom Quandl using quandl.get_table\n",
    "    # NOTE: missing data for the inputted date will NOT return a row.\n",
    "\n",
    "    # INPUT         | DATA TYPE                 | DESCRIPTION\n",
    "    # sec           | string / list of string   | security ticker\n",
    "    # start_date    | string (YYYY-MM-DD)       | start date of data\n",
    "    # end_date      | string (YYYY-MM-DD)       | end date of data (same as or after start_date)\n",
    "    # columns       | string / list of string   | columns to return\n",
    "    \n",
    "    print(f\"Quandl | START | Retriving Quandl data for security: {sec}\\n\")\n",
    "    \n",
    "    # Retrieve data using quandl.get_table\n",
    "    quandl.ApiConfig.api_key = APIs['Quandl']\n",
    "    data = quandl.get_table('QUOTEMEDIA/PRICES',\n",
    "                            ticker = sec, \n",
    "                            date = {'gte':start_date, 'lte':end_date},\n",
    "                            qopts = {'columns':list(columns)}\n",
    "                            )\n",
    "\n",
    "    print(f\"Quandl | DONE  | Returning {len(data):d} dates of data for {sec}.\\n\")\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def getAdjClose(secs,start_date,end_date):\n",
    "\n",
    "    if type(secs)==str: secs = (secs,)\n",
    "    Path(\"../data_large/EOD\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data = []\n",
    "    for sec in secs:\n",
    "        file_name = \"../data_large/EOD/\"+sec\n",
    "        if not os.path.isfile(file_name):\n",
    "            # download as CSV in local directory\n",
    "            getQuandlEODData(sec,start_date,end_date,('ticker','date','adj_close')).sort_values('date',ascending=True,ignore_index=True).set_index(['date']).to_csv(file_name)\n",
    "        \n",
    "        data.append(pd.read_csv(file_name))\n",
    "    \n",
    "    data = pd.concat(data)\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    return data.set_index(['ticker','date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2-4. Define function** to filter / clean raw data\n",
    "\n",
    "**Requirements:**\n",
    "```\n",
    "- US Equities\n",
    "- not in the automotive, financial or insurance sector over the entire period\n",
    "- end-of-day adjusted closing prices are available over the entire period\n",
    "- debt/market cap ratio is greater than 0.1\n",
    "- has feasible calculation of the ratios over the entire period: \n",
    "  - debt to market cap, \n",
    "  - return on investment, and \n",
    "  - price to earnings. \n",
    "  Including for at least one PER END DATE no more than one year old. Debt ratio of zero is OK.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getCleanZFBData(secs,start_date,end_date):\n",
    "\n",
    "    # === GET RAW DATA ============================================\n",
    "\n",
    "    raw_zacks = _getZFBData(secs,start_date,end_date).rename(columns={'per_end_date':'date'})\n",
    "    \n",
    "    # === FILTER / CLEAN ==========================================\n",
    "    \n",
    "    # US Equities only\n",
    "    zacks = raw_zacks[raw_zacks.exchange.isin(('NYSE','NASDAQ'))]  # select US stock exchanges\n",
    "    zacks = zacks[zacks.ticker_type=='S']                          # S = Securities\n",
    "    zacks = zacks[zacks.asset_type=='COM'][zacks.columns]          # COM = Common stocks\n",
    "    # zacks.drop(['exchange','ticker_type','asset_type'], axis=1, inplace=True) # drop these columns as they are no longer needed\n",
    "\n",
    "    # remove tickers without filing dates (tickers without filing dates are impossible to join on)\n",
    "    filingDate_filter = zacks[pd.isnull(zacks.filing_date)].ticker.unique()\n",
    "    zacks = zacks[~zacks.ticker.isin(filingDate_filter)]\n",
    "    \n",
    "    # not in the automotive, financial or insurance sector for any date (NOTE: there might be sector changes)\n",
    "    sector_filter = zacks[zacks.zacks_sector_code.isin((5,13))].ticker.unique() # 5 = automotive, 13 = finance (includes insurance)\n",
    "    zacks = zacks[~zacks.ticker.isin(sector_filter)]\n",
    "    # zacks.drop(['zacks_sector_code'], axis=1, inplace=True) # drop these columns as they are no longer needed\n",
    "    \n",
    "    # Debt -- Use net debt where available, total debt otherwise\n",
    "    zacks['debt'] = zacks.net_lterm_debt.fillna(zacks.tot_lterm_debt)\n",
    "\n",
    "    # EPS -- use the basic version (GAAP) if no diluted number is available.\n",
    "    zacks['eps'] = zacks.diluted_net_eps.fillna(zacks.basic_net_eps)\n",
    "    zacks.eps.clip(lower=0.001, inplace=True) # make all negative eps 0.001\n",
    "\n",
    "    # If have both quarterly & annual data for the same ticker & date, use quarterly\n",
    "    ratio_cols = ['tot_debt_tot_equity','mkt_val','ret_invst','debt','eps','shares_out','avg_d_shares']\n",
    "    zacks.set_index(['ticker','date'],inplace=True)\n",
    "    zacks_quarterly = zacks[zacks.per_type=='Q']\n",
    "    zacks_annual = zacks[zacks.per_type=='A']\n",
    "    for c in ratio_cols:\n",
    "        zacks_quarterly[c] = zacks_quarterly[c].fillna(zacks_annual[c])\n",
    "    zacks.drop(['per_type'], axis=1, inplace=True) # drop these columns as they are no longer needed\n",
    "    zacks = zacks_quarterly.reset_index()\n",
    "    \n",
    "    # debt-to-market-cap ratio greater than 0.1 AND not null (filter all since we will have enough tickers)\n",
    "    badDebtToMC_filter = zacks[(zacks.tot_debt_tot_equity<=0.1) | (pd.isnull(zacks.tot_debt_tot_equity))].ticker.unique()\n",
    "    zacks = zacks[~zacks.ticker.isin(badDebtToMC_filter)]\n",
    "\n",
    "    # other ratios are not null (ret_invst, mkt_val, eps, debt)\n",
    "    nullRatio_filter = list(zacks[pd.isnull(zacks.ret_invst) | pd.isnull(zacks.mkt_val)].ticker.unique())\n",
    "    nullRatio_filter += list(zacks[pd.isnull(zacks.eps) | pd.isnull(zacks.debt)].ticker.unique())\n",
    "    zacks = zacks[~zacks.ticker.isin(set(nullRatio_filter))]\n",
    "    \n",
    "    return zacks[['ticker','date','filing_date'] + ratio_cols]\n",
    "\n",
    "\n",
    "@functools.lru_cache(maxsize=16) # Cache the function output\n",
    "def getEodFundamentalData(secs,start_date,end_date):\n",
    "    \n",
    "    before_start_date = calcSixMonthsAgo(start_date) # get data for 6 extra months before start_date to get data reported by start_date\n",
    "\n",
    "    zacks = getCleanZFBData(secs,before_start_date,end_date)\n",
    "    tickers = zacks.ticker.unique()\n",
    "    prices = getAdjClose(tickers,before_start_date,end_date)\n",
    "    \n",
    "    # end-of-day adjusted closing prices are available\n",
    "    noEOD_filter = set()\n",
    "    \n",
    "    for sec in tickers:\n",
    "        price = prices.iloc[prices.index.get_level_values('ticker') == sec]\n",
    "        data_len = len(price)\n",
    "        if data_len < 1910 or any(pd.isnull(price.adj_close.loc[start_date:end_date])): # 1910 = number of trading days in the period 2013-07-01 -- 2021-01-31\n",
    "            # filter out the security\n",
    "            noEOD_filter.add(sec)\n",
    "            if data_len > 0: pd.DataFrame().to_csv('../data_large/EOD/'+sec) # make csv of filtered securities an empty table so we skip downloading next time\n",
    "    \n",
    "    prices = prices.iloc[~prices.index.get_level_values('ticker').isin(noEOD_filter)]\n",
    "    zacks = zacks[~zacks.ticker.isin(noEOD_filter)].set_index(['ticker','date'])\n",
    "    \n",
    "    # === JOIN PRICING DATA with FUNDAMENTAL DATA =================\n",
    "    \n",
    "    data = pd.concat([prices, zacks], axis=1)\n",
    "    \n",
    "    # === FORWARD FILL ============================================\n",
    "\n",
    "    # forward fill equity price from the previous trading day if per_end_date is not a trading date\n",
    "    data = data.transform(lambda v: v.ffill())\n",
    "\n",
    "    # === CALCULATE / RECALCULATE RATIOS ==========================\n",
    "\n",
    "    # PE (price to earnings)\n",
    "    data['PE'] = data['adj_close'] / data['eps']\n",
    "\n",
    "    # DE (debt to market cap)\n",
    "    # data['DE'] = data['tot_debt_tot_equity']*data\n",
    "\n",
    "    # ROI (return on investment)\n",
    "    data['roi'] = data['ret_invst']\n",
    "\n",
    "    # daily_data['price_to_earnings'] = daily_data['adj_close']/(eps)\n",
    "    # daily_data['debt_to_mktcap'] = (daily_data['tot_debt_tot_equity'] * daily_data['per_end_date_price'])/(daily_data['adj_close'])\n",
    "\n",
    "    # daily_data['ret_on_investment'] = (daily_data['ret_invst'] * ((daily_data.loc[:,['net_lterm_debt','tot_lterm_debt']].bfill(axis=1).iloc[:, 0]) + daily_data['mkt_val']))/((daily_data.loc[:,['net_lterm_debt','tot_lterm_debt']].bfill(axis=1).iloc[:, 0]) + (daily_data['mkt_val'] * daily_data['adj_close'] / daily_data['per_end_date_price']))\n",
    "\n",
    "    # === RETURN DATA =============================================\n",
    "    \n",
    "    index_ticker = data.index.get_level_values('ticker').unique()\n",
    "    print(f'Returning EOD + fundamental data for {len(index_ticker)} tickers.')\n",
    "\n",
    "    index_date = data.index.get_level_values('date')\n",
    "    return data.loc[(index_date>=start_date) & (index_date<=end_date)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = getEodFundamentalData('all','2014-01-01','2021-01-31')\n",
    "test.to_csv('../data_large/clean/2022-02-04.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. Fetch cleaned data using the functions above\n",
    "\n",
    "**Dates:**\n",
    "```\n",
    "January 1, 2014 - January 31, 2021*\n",
    "```\n",
    "**Note: fetch data from July 1, 2013 to get all data reported by January 1, 2014*\n",
    "\n",
    "**1-3-1. Fetch data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zacks_fc = getQuandlZFBData('FC','all','2013-07-01','2021-01-31',('ticker','exchange','per_end_date','per_type','zacks_sector_code','basic_net_eps','diluted_net_eps','tot_lterm_debt','net_lterm_debt','filing_date'))\n",
    "# zacks_fr = getQuandlZFBData('FR','all','2013-07-01','2021-01-31',('ticker','exchange','per_end_date','per_type','ret_invst','tot_debt_tot_equity'))\n",
    "# zacks_mt = getQuandlZFBData('MT','all','2013-07-01','2021-01-31',('ticker','ticker_type','asset_type'))\n",
    "# zacks_mktv = getQuandlZFBData('MKTV','all','2013-07-01','2021-01-31',('ticker','per_end_date','per_type','mkt_val'))\n",
    "# zacks_shrs = getQuandlZFBData('SHRS','all','2013-07-01','2021-01-31',('ticker','per_end_date','per_type','shares_out','avg_d_shares'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ff398735b840e154b8cbd654a97af1eda1e82713cbff18c7e563bf43d4f2a36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
